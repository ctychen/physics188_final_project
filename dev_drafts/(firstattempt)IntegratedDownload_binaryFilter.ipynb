{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2b4767",
   "metadata": {},
   "source": [
    "# An Attempt to Integrate Everything\n",
    "\n",
    "C. Chen 20251212"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170913fa",
   "metadata": {},
   "source": [
    "## Felix's code for downloading image data from observatories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f938a12-254f-4303-b52b-8b49215259f2",
   "metadata": {},
   "source": [
    "This code is heavily based on the code provided to us by Dr. Harding, Alex Toohey, Tommy Duong, and Sabrina Nazarzai on a research project using the pyaurorax package. The part of the code that downloads the data is essentially the same, with a few changes to variables and flow. The code for the multiple day downloading was also based on their code with changes to the logic and the specified parameters to allow for more control over data downloading. The saving of the frames as pdfs is original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fec5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pyaurorax as auro\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(start_time,end_time,site_id,cleanup=True):\n",
    "    aurorax = auro.PyAuroraX() #creating class instance\n",
    "    dataset_name = \"TREX_RGB_RAW_NOMINAL\" #name of dataset that will be used for extracting data\n",
    "    download = aurorax.data.ucalgary.download(dataset_name=dataset_name,start=start_time,end=end_time,site_uid=site_id) #downloads the data, takes a while\n",
    "\n",
    "    frames = [] #don't know the number of elements and frames is in a shape that is pre-assigned, making list appending easier\n",
    "\n",
    "    for filename in download.filenames: #loops over each image downloaded\n",
    "        with h5py.File(filename,'r') as f: #uses h5py file for efficient data storage and extraction\n",
    "            images = f['data/images'][:].transpose(3,0,1,2) #transposes the matrix so it is in shape [N,H,W,C] where N is frame number, H is height, \n",
    "            #W is width of image, and C is the RGB color chanel (0-2)\n",
    "            timestamp_data = f['data/timestamp'][:] #extracts the time the image was taken\n",
    "            times = [datetime.fromisoformat(t.decode('utf-8').replace(' UTC','')).replace(tzinfo=None,microsecond=0) for t in timestamp_data]\n",
    "            #the above code takes a byte object from the h5py file decodes it into a string, replaces the timezone, makes it into a datetime object,\n",
    "            #then ensures that object is timezone-naive and drops the fractional seconds\n",
    "\n",
    "            #sampling frames so that we don't have too much data as most of the images will be the same. \n",
    "            last_minute = None\n",
    "            for i,t in enumerate(times): #loops over the times\n",
    "                if (t.hour,t.minute) != last_minute: #filters out data from the same minute, captures 1 frame per minute\n",
    "                    frames.append(images[i])\n",
    "                    last_minute = (t.hour,t.minute)\n",
    "\n",
    "    #to delete the repository after samples frames from the original \n",
    "    if cleanup == True and download.filenames:\n",
    "    # Find the pyaurorax_data root directory\n",
    "        first_file = str(download.filenames[0])  # Convert to string\n",
    "        # Navigate up to find pyaurorax_data\n",
    "        path_parts = first_file.split(os.sep)\n",
    "        if 'pyaurorax_data' in path_parts:\n",
    "            idx = path_parts.index('pyaurorax_data')\n",
    "            root_dir = os.sep.join(path_parts[:idx+1])\n",
    "            try:\n",
    "                shutil.rmtree(root_dir) #removes directory\n",
    "                print(f\"Removed download directory: {root_dir}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not remove directory {root_dir}: {e}\")\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e8aad-94c1-4968-9a5b-70a2be1c4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start = datetime(2024, 1, 15, 0, 0, 0)\n",
    "end = datetime(2024, 1, 15, 23, 59, 59)\n",
    "site_uid = \"gill\" \n",
    "frames, timestamps, locations = download_data(start, end, site_uid)\n",
    "\n",
    "print(frames.shape)\"\"\"\n",
    "#testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca87eda-67a8-4561-ac41-6cd071862726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_download(start_date, end_date, site, start_hour = 0, end_hour=4):\n",
    "    #actually runs the download for multiple days if necessary, has the time preset to the time when auroras are usually expected.\n",
    "    #note: start_date, end_date are datetime objects, start_hour, end_hour are ints, site is a string.\n",
    "    \n",
    "    all_frames = [] #again, not sure how large the array or list needs to be, so using empty list\n",
    "    all_sites = []\n",
    "    \n",
    "    if type(site) == str:\n",
    "        site = [site]\n",
    "\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date: #loop over days\n",
    "        day_start = current_date.replace(hour=start_hour, minute=0, second=0) #using a datetime object and leaving the year, month, day unchanged\n",
    "        day_end = current_date.replace(hour=end_hour, minute=59, second=59)\n",
    "        \n",
    "        for loc in site: #loops over multiple sites\n",
    "            frames = download_data(day_start,day_end,site_id=loc,cleanup=True) #makes the frames\n",
    "            n = frames.shape[0]\n",
    "            all_frames.append(frames)\n",
    "            all_sites.extend([loc]*n)\n",
    "\n",
    "        current_date += timedelta(days=1) #increment the current date by 1 using timedelta\n",
    "\n",
    "    return all_frames, np.array(all_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ce8de-2104-4c10-9d54-1c8c7bba7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(frames, sites, date_str, dir_name = \"observation_images\"):\n",
    "    #function saves the frames \n",
    "    out_dir = f'{dir_name}_{date_str}'\n",
    "    os.makedirs(out_dir,exist_ok=True) #makes a new directory, doesn't crash if the directory already exists\n",
    "    for i in range(frames.shape[0]):\n",
    "        plt.imsave(os.path.join(out_dir, f\"{sites[i]}_frame_{i:07d}.png\"),frames[i]) #saves the images as png for classification\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5a4f7-9129-479e-b1f8-293eef6fb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cell\n",
    "#note datetime follow this pattern:\n",
    "#(xxxx, xx, xx, xx, xx, xx)\n",
    "#(year, month, day, hour, minute, second)\n",
    "#all arguments are not necessary\n",
    "# may 10-13 2024 geomagnetic storm as baseline \n",
    "start_date = datetime(2024, 10, 8) #datetime(2024, 10, 11) #datetime(2025, 9, 30) #datetime(2025, 11, 12) #datetime(2024,9,17) #datetime(2024,5,10)\n",
    "end_date = datetime(2024, 10, 8) #datetime(2024, 10, 11) #datetime(2025, 9, 30) #datetime(2025, 11, 13) #datetime(2024,9,17) #datetime(2024,5,13)\n",
    "start_hour = 2 #4 #2 \n",
    "end_hour= 6 #5 #6\n",
    "# site = [\"fsmi\",\"luck\",\"pina\",\"rabb\",\"yknf\",\"gill\",\"atha\"]\n",
    "site = [\"fsmi\", \"luck\", \"pina\"]\n",
    "\n",
    "all_frames, all_loc = run_download(start_date=start_date,end_date=end_date,site=site, start_hour=start_hour, end_hour=end_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be556eeb-71a8-49dd-b4fd-3d6998d27217",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_frames = []\n",
    "for frames in all_frames:\n",
    "    list_of_frames.extend(frames)\n",
    "list_of_frames = np.array(list_of_frames)\n",
    "\n",
    "date_str = \"20241008\"\n",
    "save_frames(list_of_frames, all_loc, date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = auro.PyAuroraX()\n",
    "print(test.data.ucalgary.list_datasets())\n",
    "obs = test.data.ucalgary.list_observatories('trex_rgb')\n",
    "for i in range(len(obs)):\n",
    "    print(obs[i].uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b4b10",
   "metadata": {},
   "source": [
    "## Bringing in Ishaan's code for colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9db00-e6f0-4d7c-b683-0a8f2b3ba890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib import pyplot as plt, image as mpimg\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.color import rgb2hsv, rgb2lab\n",
    "import zipfile\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ceec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The main function\n",
    "def binary_filtering(img, K=3, luminosity_threshold=40,\n",
    "        hsv_green=(60, 125),\n",
    "        hsv_red1=(0, 10),\n",
    "        hsv_red2=(350, 360),\n",
    "        hsv_blue=(220, 250),\n",
    "        max_hue_std=15\n",
    "    ):\n",
    "    ## Preprocessing\n",
    "    if img.dtype != np.float32 and img.dtype != np.float64:\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    flat = img.reshape(-1, 3)\n",
    "\n",
    "    ## Cluster\n",
    "    kmeans = KMeans(n_clusters=K, n_init=\"auto\").fit(flat)\n",
    "    # remove alpha if present\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = img[..., :3]\n",
    "    flat = img.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=K, n_init=\"auto\").fit(flat)\n",
    "    labels = kmeans.labels_.reshape(h, w)\n",
    "\n",
    "    ## Color\n",
    "    hsv = rgb2hsv(img)\n",
    "    H = hsv[:, :, 0] * 360\n",
    "\n",
    "    lab = rgb2lab(img)\n",
    "    L = lab[:, :, 0]\n",
    "\n",
    "    ## Cuts\n",
    "    for k in range(K):\n",
    "        mask = (labels == k)\n",
    "        cluster_lum = np.max(L[mask])\n",
    "\n",
    "        if cluster_lum < luminosity_threshold:\n",
    "            continue\n",
    "            \n",
    "        cluster_hue = np.mean(H[mask])\n",
    "        cluster_hue_std = np.std(H[mask])\n",
    "\n",
    "        # Skip clusters with inconsistent hue\n",
    "        if cluster_hue_std > max_hue_std:\n",
    "            continue\n",
    "\n",
    "        # Check if the cluster hue corresponds to aurora colors\n",
    "        green = hsv_green[0] <= cluster_hue <= hsv_green[1]\n",
    "        red = (hsv_red1[0] <= cluster_hue <= hsv_red1[1]) or (hsv_red2[0] <= cluster_hue <= hsv_red2[1])\n",
    "        blue = hsv_blue[0] <= cluster_hue <= hsv_blue[1]\n",
    "\n",
    "        if green or red or blue:\n",
    "            return True\n",
    "    ## Additional check: hue at max luminosity pixel\n",
    "    max_idx = np.unravel_index(np.argmax(L), L.shape)\n",
    "    max_hue = H[max_idx]\n",
    "\n",
    "    green = hsv_green[0] <= max_hue <= hsv_green[1]\n",
    "    red = (hsv_red1[0] <= max_hue <= hsv_red1[1]) or (hsv_red2[0] <= max_hue <= hsv_red2[1])\n",
    "    blue = hsv_blue[0] <= max_hue <= hsv_blue[1]\n",
    "\n",
    "    if green or red or blue:\n",
    "        return True\n",
    "    ## If no prior condition is met:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb68de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"obs_test\"\n",
    "image_files = [f for f in os.listdir(test_folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "N = len(image_files)\n",
    "\n",
    "filtered = [False]*N\n",
    "\n",
    "for i,image in enumerate(image_files):\n",
    "    img_path = os.path.join(test_folder, image)\n",
    "    img = mpimg.imread(img_path)\n",
    "    truth = binary_filtering(img)\n",
    "    filtered[i]=truth\n",
    "print(np.sum(filtered),N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c85ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_indices = [i for i, val in enumerate(filtered) if not val]\n",
    "idx = false_indices[20:40]\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for idx, image_idx in enumerate(idx):\n",
    "    img_path = os.path.join(test_folder, image_files[image_idx])\n",
    "    img = mpimg.imread(img_path)\n",
    "    \n",
    "    plt.subplot(4, 5, idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(image_files[image_idx])\n",
    "\n",
    "plt.suptitle(\"Negative / No Aurora Images Detected by Binary Filtering\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "true_indices = [i for i, val in enumerate(filtered) if val]\n",
    "idx = true_indices[20:40]\n",
    "plt.figure(figsize=(15, 8))\n",
    "for idx, image_idx in enumerate(idx):\n",
    "    img_path = os.path.join(test_folder, image_files[image_idx])\n",
    "    img = mpimg.imread(img_path)\n",
    "    \n",
    "    plt.subplot(4, 5, idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(image_files[image_idx])\n",
    "plt.suptitle(\"Positive Aurora Images Detected by Binary Filtering\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9256a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "from skimage.color import rgb2hsv\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "### Note this is not really needed, it was just a sanity check to see\n",
    "### what color an aurora is lol\n",
    "### Also note that this gets mean dominant hue, so the actual range is larger\n",
    "\n",
    "# Suppress the MKL KMeans warning on Windows\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "\n",
    "def get_dominant_hue(folder_path, num_clusters=3, min_saturation=0.2, min_value=0.1, max_images=3000):\n",
    "    \"\"\"\n",
    "    Computes robust hue ranges for green, red, and blue auroras from a folder of images.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: folder containing aurora images\n",
    "    - num_clusters: number of dominant hues to find per image\n",
    "    - min_saturation: ignore pixels with S < this\n",
    "    - min_value: ignore pixels with V < this\n",
    "    - max_images: only process first N images\n",
    "    \n",
    "    Returns:\n",
    "    - hue_ranges: dict with keys 'green', 'red', 'blue', each a (min,max) tuple\n",
    "    \"\"\"\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    image_files = image_files[:max_images]  # limit to first max_images\n",
    "    \n",
    "    all_cluster_hues = []\n",
    "\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = mpimg.imread(img_path)\n",
    "\n",
    "        # Normalize to 0-1 if needed\n",
    "        if img.dtype != np.float32 and img.dtype != np.float64:\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        # remove alpha if present\n",
    "        if img.ndim == 3 and img.shape[2] == 4:\n",
    "            img = img[..., :3]\n",
    "        flat = img.reshape(-1, 3)\n",
    "\n",
    "        # Convert to HSV\n",
    "        hsv = rgb2hsv(img)\n",
    "        H = hsv[:, :, 0] * 360  # degrees\n",
    "        S = hsv[:, :, 1]\n",
    "        V = hsv[:, :, 2]\n",
    "\n",
    "        # Mask dark / unsaturated pixels\n",
    "        mask = (V > min_value) & (S > min_saturation)\n",
    "        H_masked = H[mask].reshape(-1, 1)\n",
    "        if H_masked.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Cluster hues in 1D using MiniBatchKMeans with large batch_size to avoid MKL warning\n",
    "        k = min(num_clusters, H_masked.shape[0])\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, n_init=\"auto\", batch_size=5000).fit(H_masked)\n",
    "        cluster_centers = kmeans.cluster_centers_.flatten()\n",
    "\n",
    "        # Save cluster centers for aggregation\n",
    "        all_cluster_hues.extend(cluster_centers)\n",
    "\n",
    "    all_cluster_hues = np.array(all_cluster_hues)\n",
    "\n",
    "    # Assign clusters to approximate color ranges\n",
    "    green_hues = all_cluster_hues[(all_cluster_hues >= 80) & (all_cluster_hues <= 140)]\n",
    "    red_hues = all_cluster_hues[(all_cluster_hues <= 20) | (all_cluster_hues >= 340)]\n",
    "    blue_hues = all_cluster_hues[(all_cluster_hues >= 200) & (all_cluster_hues <= 260)]\n",
    "\n",
    "    def compute_range(arr):\n",
    "        if len(arr) == 0:\n",
    "            return None\n",
    "        return (np.min(arr), np.max(arr))\n",
    "\n",
    "    hue_ranges = {\n",
    "        \"green\": compute_range(green_hues),\n",
    "        \"red\": compute_range(red_hues),\n",
    "        \"blue\": compute_range(blue_hues)\n",
    "    }\n",
    "\n",
    "    return hue_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"obs_train\" \n",
    "hue_ranges = get_dominant_hue(folder)\n",
    "print(\"Calibrated hue ranges (degrees):\")\n",
    "print(hue_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = \"obs_train/luck_frame_0000150.png\" # aurora with moon\n",
    "# img_path = \"obs_train/pina_frame_0000341.png\" # no aurora no moon\n",
    "img_path = \"obs_train/pina_frame_0000333.png\" # bright red/green aurora, no moon\n",
    "img = mpimg.imread(img_path)\n",
    "\n",
    "# Convert to float 0-1 if needed\n",
    "if img.dtype != np.float32 and img.dtype != np.float64:\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "# remove alpha if present\n",
    "if img.ndim == 3 and img.shape[2] == 4:\n",
    "    img = img[..., :3]\n",
    "\n",
    "# Convert to LAB color space\n",
    "lab = rgb2lab(img)\n",
    "L = lab[:, :, 0]  # L channel = lightness/luminosity\n",
    "print(np.max(L))\n",
    "\n",
    "max_idx = np.unravel_index(np.argmax(L), L.shape)\n",
    "hsv = rgb2hsv(img)\n",
    "H = hsv[:, :, 0] * 360  # degrees\n",
    "\n",
    "# Hue at the brightest pixel\n",
    "max_hue = H[max_idx]\n",
    "print(\"Hue at max luminosity pixel (degrees):\", max_hue)\n",
    "\n",
    "# Show the image with max luminosity pixel marked - side by side with original\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(f\"Max Luminosity Pixel Hue: {max_hue:.1f}Â°\")\n",
    "ax[0].scatter([max_idx[1]], [max_idx[0]], color='red', s=50, marker='x')\n",
    "ax[1].imshow(img)\n",
    "ax[1].set_title(f\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
